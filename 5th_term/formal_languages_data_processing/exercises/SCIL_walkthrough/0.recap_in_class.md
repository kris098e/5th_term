# compiler phases in order
## Scanner
stream of chars comes in, want stream of tokens out. 
- Generates a DFA first
- matches on regular expressions
- accept states becomes the output of the scanner for a certain stream of characters
- Use Lexxer
	- fx Flex is a library which can be used.
	- Have reserved keywords
	- list of regular expressions. When the lexxer matches on them, then token is outputted
	- have some priorites for error handling. Fx the shift/reduce conflict. How to handle it?
## Parser
input is a stream of tokens, and the output is the AST
- we make the AST from the parsing table
	- The parsing table is the grammar
	- YACC, Bison
	- in Ply.flex it abuses the docstring, which will make the context-free grammar.
- LL(1)
- LR(1)
- LALR(1)
	- delays errors compared to the LR(1)
## Symbol collection
translate the tokens we see into values with some structure
- keep track of scope
	- think about the picture with the boxes for each scope, where a box may be inside another box.
- symbols can have categories
	- function
	- parameter
	- variables / identifiers
- only functions can make a new scope in SCIL
## Type checking
input is AST with the symbol collection added to it
- fx check that the variable exists in the current scope
- check if the variable is an int or something else
	- fx when doing expressions between two values, they have to be compatible
output:
- an error if invalid input, else proceed
- The only type checking we do in SCIL
	- check if the variable exists, and within the correct scope
## Code generation
keep up invariants
input AST
visitors
- fx while loops will after the previsit where it has made the label, call the visitor for the expression we need to evaluate if we want to go into the while.
Invariants are kept true, fx the stack is a stack machine for expressions, return value is on top of the stack
output is the array of instructions, which is an array of a python class
## Emit
Input is just the array from code gen, and the output is x86 assembly.

