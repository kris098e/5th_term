# Universal hashing
## Why universal hashing is wanted
![[Pasted image 20231120083703.png]]
![[Pasted image 20231120083716.png]]

![[Pasted image 20231120083911.png]]
![[Pasted image 20231120083958.png]]
![[Pasted image 20231120084244.png]]
Makes sense what is written, **read carefully**
![[Pasted image 20231120084437.png]]
`first bullet point:` Makes sense that the length of the linkedlist for which this `k` is hashed to is $\leq \frac{n}{m}$ since the probability of hashing the element to a certain spot is $\frac{1}{m}$ and we have inserted `n`-elements into the spot.
`seconds bullet point:` Makes sense that the length is expected to be the same as before but with `+1` since we have already met the element before so that it will be hashed to that spot again, therefore `+1`. Should probably be $\frac{n-1}{m}+1$ since $k$ was part of the set
![[Pasted image 20231120085020.png]]
![[Pasted image 20231120085219.png]]
it states? (`just read what the explanation of ` $Y_{k}$)
$$Y_{k}=\mid \{e\in S-h\mid h(k)=h(e)\}\mid$$
![[Pasted image 20231120085515.png]]
it is $\leq$ since looking at the state:
$$p(h(k) = h(e)) \leq \frac{1}{m}$$
`see the 3rd photo on top of this`
![[Pasted image 20231120091429.png]]
States what I have already stated above before we got the formal proof with the use of random indicator variables.
![[Pasted image 20231120091752.png]]
We see that $\alpha$ is just a constant, therefore the operations are of $O(1)$.

## How to achieve universal hashing
### Cormen approach
`p is a prime number, which is the upper bound of the size of the universe`
![[Pasted image 20231120092227.png]]
remember that you choose an element in $Z_{p}^*$ for `a` and also for `b` in the other set.
![[Pasted image 20231120092327.png]]
`The first bullet point` is just the set of all hash functions where 
$$h_{ab}=Z_{p}\to Z_{m}$$
and for $Z_{p}^*$ there are $p-1$ options, and for $Z_{p}$ there are $p$ options, therefore there are $p \cdot(p-1)=p^2-p$ hashfunctions that fits the criteria. 
- We dont have to know the proof
To get the random universal hashfunction, we just pick a random `a` and `b` and let this be our hashfunction
### Kleinberg and tardos (LISTEN IN CLASS)
In this, `JÃ¸rgen` made a big deal out of the fact that in Cormen they use $p\geq\mid U\mid$ so p is larger than the size of the universe, which `p` is `not` in Kleinberg tardos.
![[Pasted image 20231120094336.png]]
**we split each number up into multiple bit strings for length** $\log_{2}(p)$
`identifying the universe by vectors` means that we just identify fx `1` in binary with `p` bits. `p>=n` for some `p` close to `n`.  Then we only need. $\frac{\log N}{\log n}$  spots to make the random hash functions with the property of universal hashing

We use `N` now as the number of numbers. `p` is again a prime. 
![[Pasted image 20231120095122.png]]
This is just an example of choosing some vectors which identifies the universe.
![[Pasted image 20231120095347.png]]
We sum up all of the $a_{i}$ with $x_{i}$ where we have split input $x$ into multiple small vectors, Look at the proof for an example
![[Pasted image 20231120095548.png]]
![[Pasted image 20231120095608.png]]
![[Pasted image 20231120095706.png]]
![[Pasted image 20231120095835.png]]
![[Pasted image 20231120095856.png]]





# Perfect Hashing
- The probability that we have any collisions when we use a universal hash function into a table of size $n^2$ where $n=\mid S\mid$ is $\frac{1}{2}$.
`remember to do this with random indicator variables` 
![[Pasted image 20231218160804.png]]
probability of collision is $\frac{1}{n^2}$.  there are ${ n \choose 2}$ ways to collide. Therefore, the expected number of collisions is: $\frac{{n \choose 2}}{n^{2}}< \frac{1}{2}$. Bound this by Markovs inequality
$$p(Z \geq 1) \leq \frac{E(Z)}{1}=E(Z)<\frac{1}{2}$$
probability of no collision $p(Z=0)=1-p(Z=1)\implies p(Z=0)\geq \frac{1}{2}$.
Expected number of times we run the algorithm $\frac{1}{p}=\frac{1}{\frac{1}{2}}<2$.
But we now still use $n^2$ memory.

Use $n^2$ in the 2nd level of hash table.

let
$$m_{j}=\forall x\in n\mid \{ x \mid h(x)=j\}\mid$$
And use table size of
$$m_{j}^2$$
for storage in this 2nd hash table. This means that $m_{j}$ is the number of elements hashed to the j'th index. We will then need to store the hash function for the table, and this much storage for each. Let us look at the expected value of storage in all the 2nd hash tables
$$E\left( \sum_{i=0}^{n-1} m_{j}^{2}\right)$$
Note that it does make sense to take the expected value of this, as $m_{j}$ depends on the random hash function.
we use that
$m^{2}=m+2 {m\choose 2}=m+m(m-1)$
`note that m=n`
$$\begin{align}
E\left( \sum_{i=0}^{n-1} m_{i}^2 \right)=E\left(\sum_{i=0}^{n-1}m_{i}+2 {m_{i}\choose 2}\right) \\
= E(\sum_{i=0}^{n-1}m_{i})+E\left(\sum_{i=0}^{n-1}2 {m_{i}\choose 2}\right) \\
=E(m)+2E\left(\sum_{i=0}^{n-1} {m_{i} \choose 2}\right) \\
=m+2E(r)
\end{align}
$$
the `m` comes from the fact we sum up all that is mapped to the i'th position. 
$\sum_{i=0}^{n-1} {m_{i} \choose 2}$ is simply the total number of collisions. I.e we sum up all the collisions.
$$E(r)={m\choose 2}\cdot \frac{1}{m} = \frac{m-1}{2}$$
$$E\left(\sum_{i=0}^{n-1} m_{i}^{2}\right)=m+2\frac{m-1}{2}\lt 2m$$
We can then bound the probability that the expected value is more than 4m:
$$p\left( \sum_{i=0}^{n-1}m_{i}^2 >4m\right)\leq \frac{E\left( \sum_{i=0}^{n-1}m_{i}^2 \right)}{4m}=\frac{2m}{4m}=\frac{1}{2}$$
This means the probability that we have to use more than $4m$ space is $\frac{1}{2}$.

![[Pasted image 20231121135057.png]]
- remember keys are static, i.e number of keys does not change
![[Pasted image 20231121135141.png]]
- use multiple hash functions, the coliding elements in the first hashtable will be hashed with a specialized hashfunction in the 2nd hash table
![[Pasted image 20231121135422.png]]
- $n_{j}$ is the set of elements which has to spot `j` in the outer hash table
![[Pasted image 20231121135541.png]]

![[Pasted image 20231121140058.png]]
![[Pasted image 20231121140226.png]]

![[Pasted image 20231121140602.png]]
- What is calculated here is simply the propability that we have more than or equal to 1 collisions for `Z` where `Z` denotes the number of collisions. This is $< \frac{1}{2}$, meaning that the probability of no collisions is $1-\frac{1}{2}$ which is more than 50%. 
- Since we want to ensure that there are no collisions, if we have collisions then we will simply try using new hash function $h$ until we obtain no collisions, ensuring a constant lookup time.
	- we may try to do so infinitely many times, and end up with a geometric distribution, meaning the expected number of times we have to try new hasfunctions is `2`
- this is only if we use choose the hashtable to be $n^2$ big.
![[Pasted image 20231121141902.png]]

![[Pasted image 20231121142037.png]]

space:
![[Pasted image 20231121142234.png]]
`according to the definition in cormen:` just menas the universal hashfunction we proved in cormen.
![[Pasted image 20231121143453.png]]
It makes sense that $$E\left( \sum_{j=0}^{m-1} n_{j}\right)=n$$
as we simply sum up all of the elements which are mapped to the $j^{th}$ position, and as all of the elements are mapped to position, that means that it is `n`.
![[Pasted image 20231121144609.png]]
$$E(r)$$ can be calculated as the number of possible ways to make collisions times the probability, and since we use universal hashing this will be $\frac{1}{m}$ chance. And we have $m=n$.
![[Pasted image 20231121144935.png]]
![[Pasted image 20231121145202.png]]